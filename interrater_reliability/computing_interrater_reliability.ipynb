{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2e0e2d",
   "metadata": {},
   "source": [
    "### Import libraries and preprocess manual annotation files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for files to HB annotation and UY annotation\n",
    "HB_PATH = r\"C:\\Users\\seohy\\nlplearnerdata\\interrater_reliability\\HB_annotation.xlsx\"\n",
    "UY_PATH = r\"C:\\Users\\seohy\\nlplearnerdata\\interrater_reliability\\UY_annotation.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and process HB annotation\n",
    "HB_sheets = pd.read_excel(HB_PATH, sheet_name = None)\n",
    "\n",
    "# Combine sheets into one df\n",
    "HB_combined = pd.concat(HB_sheets.values(), axis = 0, ignore_index = True)\n",
    "\n",
    "# Drop and select relevant columns\n",
    "HB_combined = HB_combined[[\"ID\", \"FORM\", \"POS\", \"HEAD\", \"DEPREL\"]]\n",
    "\n",
    "# Rename columns to include HB\n",
    "HB_combined = HB_combined.rename(\n",
    "    {\n",
    "        \"ID\": \"ID_HB\", \n",
    "        \"FORM\": \"FORM_HB\",\n",
    "        \"POS\": \"POS_HB\",\n",
    "        \"HEAD\": \"HEAD_HB\",\n",
    "        \"DEPREL\": \"DEPREL_HB\"\n",
    "    }, \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c70873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and verify preprocessing results\n",
    "HB_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a12521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and process UY annotation\n",
    "UY_sheets = pd.read_excel(UY_PATH, sheet_name = None)\n",
    "\n",
    "# Combine sheets into one df\n",
    "UY_combined = pd.concat(UY_sheets.values(), axis = 0, ignore_index = True)\n",
    "\n",
    "# Drop and select only relevant columns\n",
    "UY_combined = UY_combined[[\"ID\", \"FORM\", \"POS\", \"HEAD\", \"DEPREL\"]]\n",
    "\n",
    "# Rename columns to include UY\n",
    "UY_combined = UY_combined.rename(\n",
    "    {\n",
    "        \"ID\": \"ID_UY\", \n",
    "        \"FORM\": \"FORM_UY\",\n",
    "        \"POS\": \"POS_UY\",\n",
    "        \"HEAD\": \"HEAD_UY\",\n",
    "        \"DEPREL\": \"DEPREL_UY\"\n",
    "    }, \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1710398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and verify preprocessing results\n",
    "UY_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809de263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two processed dfs\n",
    "df_combined = pd.concat([HB_combined, UY_combined], axis = 1)\n",
    "\n",
    "# Reorder columns to align Align rows\n",
    "df_combined = df_combined[[\n",
    "    \"ID_HB\",\n",
    "    \"ID_UY\",\n",
    "    \"FORM_HB\",\n",
    "    \"FORM_UY\",\n",
    "    \"POS_HB\",\n",
    "    \"POS_UY\",\n",
    "    \"HEAD_HB\",\n",
    "    \"HEAD_UY\",\n",
    "    \"DEPREL_HB\",\n",
    "    \"DEPREL_UY\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and verify preprocessing results\n",
    "df_combined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9388b0",
   "metadata": {},
   "source": [
    "### !!Sanity check!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b32b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sainty check - tokenization is the same\n",
    "# Should return nothing (no rows) if tokenization matches and align\n",
    "df_combined[df_combined[\"FORM_HB\"] != df_combined[\"FORM_UY\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b002bf",
   "metadata": {},
   "source": [
    "### Compute interrater reliability for POS and DP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen's kappa for POS \n",
    "pos_kappa = cohen_kappa_score(df_combined[\"POS_HB\"], df_combined[\"POS_UY\"])\n",
    "print(f\"Cohen's kappa for POS annotation: {pos_kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964280d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the total number of tokens\n",
    "tokens = len(df_combined)\n",
    "\n",
    "# Compute UAS and LAS\n",
    "same_heads = (df_combined[\"HEAD_HB\"] == df_combined[\"HEAD_UY\"]).sum()  \n",
    "UAS =  same_heads / tokens * 100\n",
    "same_heads_and_relation = ((df_combined[\"HEAD_HB\"] == df_combined[\"HEAD_UY\"]) & (df_combined[\"DEPREL_HB\"] == df_combined[\"DEPREL_UY\"])).sum()\n",
    "\n",
    "LAS = same_heads_and_relation / tokens  * 100\n",
    "\n",
    "# Print output of UAS and LAS\n",
    "print(f\"UAS for DP: {UAS}%\")\n",
    "print(f\"LAS for DP: {LAS}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374edb9a",
   "metadata": {},
   "source": [
    "### Compute interrater reliability for learner errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d8131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplearnerdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
