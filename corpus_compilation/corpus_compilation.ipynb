{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482deb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f128e1c",
   "metadata": {},
   "source": [
    "## Replacing special characters before convering into XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3abb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of raw texts in .txt \n",
    "folder_path = r\"PATH\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "print(os.path.exists(folder_path))\n",
    "\n",
    "# Path of texts with converted special chracters\n",
    "output_folder = r\"PATH\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(os.path.exists(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6702cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement map for XML string\n",
    "replacements = {\n",
    "    \"&\": \"&amp;\",   # Must replace first\n",
    "    \"<\": \"&lt;\",\n",
    "    \">\": \"&gt;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\",\n",
    "    \"_x000D_\": \"\", # Replace carriage returns, already newline in .txt \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3989645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert special chracters of one .txt text\n",
    "def escape_xml_chars(text, file_path):\n",
    "    # For each pair in the replacement map\n",
    "    for char, replacement in replacements.items():\n",
    "        # If special char = dict key in text\n",
    "        if char in text:\n",
    "            # Replace and print that replacement occurred\n",
    "            text = text.replace(char, replacement)\n",
    "            print(f\"Replaced {char} → '{replacement} for {file_path}\")\n",
    "    # Return transformed text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the folder_path\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Transform and save text into escaped_content  \n",
    "    escaped_content = escape_xml_chars(text, file_path)\n",
    "\n",
    "    # Save transformed text to output folder (keeping same filename)\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(escaped_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d96457",
   "metadata": {},
   "source": [
    "## Creating a basic dataframe for XML tag and attribute\n",
    "\n",
    "Cf) Note that language_socore and content_score shall be added in the next section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f48f7",
   "metadata": {},
   "source": [
    "1. &lt;entry&gt;: a single text by one learner at one time period\n",
    "\n",
    "- id: a unique identifier for each text (i.e., filename)\n",
    "- time_period: year and term when the data was collected (i.e., \"24-2\")\n",
    "- task: identifier for the specific writing prompt or task (e.g., \"T1\")\n",
    "- language_score: score learner received on language\n",
    "- content_score: score learner received on content\n",
    "\n",
    "2. &lt;learner&gt;: information about the learner who wrote the text\n",
    "\n",
    "- id: A unique identifier for the learner (i.e., 학번)\n",
    "- grade: the grade of the learner when the text was written\n",
    "\n",
    "3. Text-related tags\n",
    "\n",
    "- &lt;text_original&gt;: the original text written by the learner\n",
    "- &lt;text_error&gt;: the error-tagged version of the original text\n",
    "- &lt;text_corrected&gt;: the corrected version of the text\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eaeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for creating dataframes\n",
    "entry_id_list = []\n",
    "time_period_list = []\n",
    "task_list = []\n",
    "learner_id_list = []\n",
    "grade_list = []\n",
    "text_original_list = []\n",
    "text_error_list = []\n",
    "text_corrected_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c517c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each transformed text\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "    entry_id_list.append(filename[:8]) # Save filename w/hout .txt\n",
    "    time_period_list.append(\"24-2\") # All periods currently 24-2\n",
    "    task_list.append(\"T\" + filename[0]) # Concat \"T\" w/h task number \n",
    "    learner_id_list.append(filename[3:8]) # Save 학번 from filename\n",
    "    grade_list.append(filename[3]) # Save first number from 학번\n",
    "    \n",
    "    # Read and work with file content\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # Before error tagging, all same as original text \n",
    "        text = file.read()\n",
    "        text_original_list.append(text)\n",
    "        text_error_list.append(text)\n",
    "        text_corrected_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with the saved lists\n",
    "dict_corpus = {}\n",
    "\n",
    "dict_corpus[\"entry_id\"] = entry_id_list\n",
    "dict_corpus[\"time_period\"] = time_period_list\n",
    "dict_corpus[\"task\"] = task_list\n",
    "dict_corpus[\"learner_id\"] = learner_id_list\n",
    "dict_corpus[\"grade\"] = grade_list\n",
    "dict_corpus[\"text_original\"] = text_original_list\n",
    "dict_corpus[\"text_error\"] = text_error_list\n",
    "dict_corpus[\"text_corrected\"] = text_corrected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of values for each key\n",
    "# Check that same number for all key\n",
    "# Set index=list(range(1, 605) when creating dataframe\n",
    "value_counts = {key: len(values) for key, values in dict_corpus.items()}\n",
    "print(value_counts)\n",
    "\n",
    "# Create and show dataframe of corpus data\n",
    "df = pd.DataFrame(dict_corpus, index=list(range(1, 605)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cccf7e5",
   "metadata": {},
   "source": [
    "## Adding language_socore and content_score to df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2451a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for saving language and content scores for each task \n",
    "T1_cont_list = [] # Task 1, content scores\n",
    "T1_lang_list = [] # Task 1, language scores\n",
    "T2_cont_list = [] # Task 2, content scores\n",
    "T2_lang_list = [] # Task 2, language scores\n",
    "\n",
    "# Same entry ids as above, needed for matching scores with merge\n",
    "entry_id_list_T1 = []\n",
    "entry_id_list_T2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ddd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv of T1 scores\n",
    "task1_scores = pd.read_csv(\"student_scores_task1.csv\")\n",
    "\n",
    "# Iterate through each rows in the csv\n",
    "for index, row in task1_scores.iterrows():\n",
    "    # Combine  number + student_id, check if in \"total\" folder\n",
    "    id = row[\"student_id\"]\n",
    "    entry_id = \"1_\" + id\n",
    "    file_name = \"1_\" + id + \".txt\"\n",
    "\n",
    "    # If combination in \"total\" folder, retrieve language and content score\n",
    "    if file_name in os.listdir(output_folder):\n",
    "        entry_id_list_T1.append(entry_id)\n",
    "        T1_cont_list.append(row[\"T1_Cont\"])\n",
    "        T1_lang_list.append(row[\"T1_Lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same process for T2\n",
    "# Read in the csv of T2 scores\n",
    "task2_scores = pd.read_csv(\"student_scores_task2.csv\")\n",
    "\n",
    "# Iterate through each rows in the csv\n",
    "for index, row in task2_scores.iterrows():\n",
    "    # Combine  number + student_id, check if in \"total\" folder\n",
    "    id = row[\"student_id\"]\n",
    "    entry_id = \"2_\" + id\n",
    "    file_name = \"2_\" + id + \".txt\"\n",
    "\n",
    "    # If combination in \"total\" folder, retrieve language and content score\n",
    "    if file_name in os.listdir(output_folder):\n",
    "        entry_id_list_T2.append(entry_id)\n",
    "        T2_cont_list.append(row[\"T2_Cont\"])\n",
    "        T2_lang_list.append(row[\"T2_Lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of scores with the saved lists\n",
    "dict_scores = {}\n",
    "\n",
    "# Connect the lists in order; order is not rearranged\n",
    "dict_scores[\"entry_id\"] = entry_id_list_T1 + entry_id_list_T2\n",
    "dict_scores[\"content_score\"] = T1_cont_list + T2_cont_list\n",
    "dict_scores[\"language_score\"] = T1_lang_list + T2_lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64803d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of values for each key, same as creating original df above\n",
    "value_counts = {key: len(values) for key, values in dict_scores.items()}\n",
    "print(value_counts)\n",
    "\n",
    "df_socres = pd.DataFrame(dict_scores, index=list(range(1, 605)))\n",
    "df_socres.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes together\n",
    "# Merge scores based on matching with \"entry_id\" or filename\n",
    "entries_total = df.merge(df_socres, on=\"entry_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2facd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that merge is done properly with no NaN values\n",
    "print(entries_total.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eed120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the dataframe of corpus data\n",
    "entries_total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Svae the dataframe of corpus data\n",
    "entries_total.to_csv(\"entries_total_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973ab50",
   "metadata": {},
   "source": [
    "## Convert dataframe into and save XML format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list for storing entries\n",
    "xml_entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd63fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataframe \n",
    "with open(\"entries_total_raw.csv\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    # Create DictReader to treat/read each csv row like a dictionary\n",
    "    # The csv columns become its keys, and the cells become their values\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    # For each row of the csv file\n",
    "    for row in reader:\n",
    "        # Create each xml entry using string formatting  \n",
    "        xml_entries.append(f'''\\t\\t<entry id=\"{row['entry_id']}\" time_period=\"{row['time_period']}\" task=\"{row['task']}\" content_score=\"{row['content_score']}\" language_score=\"{row['language_score']}\"> \n",
    "            <learner id=\"{row['learner_id']}\" grade=\"{row['grade']}\"/> \n",
    "            <text_original>{row['text_original']}</text_original>\n",
    "            <text_error>{row['text_error']}</text_error>\n",
    "            <text_corrected>{row['text_corrected']}</text_corrected>\n",
    "        </entry>\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap all entries inside a root tag\n",
    "xml_content = \"<writings>\\n\" + \"\\n\".join(xml_entries) + \"\\n</writings>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corpus entries into XML\n",
    "with open(\"entries_total_raw.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(xml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae6be8",
   "metadata": {},
   "source": [
    "## Choose 20 random files for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d708c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of files in output_folder\n",
    "all_file_names = [file for file in os.listdir(output_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fa6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducing results\n",
    "random.seed(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and print random file names\n",
    "num_files = 20\n",
    "random_files = random.sample(all_file_names, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sampled results based on seed\n",
    "for file in random_files:\n",
    "    print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplearnerdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
